---
defaults: 
  - dataset: a9a

centralized: False
device: "cpu"

n_estimators_client: ${dataset.clients.n_estimators_client}
task_type: ${dataset.task_type}
client_num: ${dataset.clients.client_num}



XGBoost:
  _target_:  ${dataset.xgb._target_}
  objective: ${dataset.xgb.objective}
  learning_rate: .1
  max_depth: ${dataset.clients.xgb.max_depth}
  n_estimators: ${dataset.clients.n_estimators_client}
  subsample: 0.8
  colsample_bylevel: 1
  colsample_bynode: 1
  colsample_bytree: 1
  alpha: 5
  gamma: 5
  num_parallel_tree: 1
  min_child_weight: 1


model:
  # model config

strategy:
  _target_: flwr.server.strategy.FedXgbNnAvg 
  _recursive_: true #everything to be instantiated
  fraction_fit: 1.0 
  fraction_evaluate: 0.0 # no clients will be sampled for federated evaluation (we will still perform global evaluation)
  min_fit_clients: 1
  min_evaluate_clients: 1
  min_available_clients: ${client_num}
  accept_failures: False

client:
  # client config

run_experiment:
  num_rounds: ${dataset.clients.num_rounds}
  batch_size: 64
  fraction_fit: 1.0
  min_fit_clients: 1
  num_cpus_per_client: 1
  fit_config:
    num_iterations: 100

val_ratio: 0.0
batch_size: "whole"